{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chasslayy/Melanin-Match-AI/blob/main/Melanin_Match_AI_Colab_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c694dcf0",
      "metadata": {
        "id": "c694dcf0"
      },
      "source": [
        "# Melanin Match AI\n",
        "**Machine Learning Final Project — Mercy University (CISC 550)**  \n",
        "**Student:** Chastity Lewis  \n",
        "**Semester:** Fall 2025  \n",
        "\n",
        "### Objective\n",
        "Build a supervised learning model that predicts foundation shades for diverse skin tones using image data and classification models (SVM, kNN, and a CNN-based deep learning model).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06848020",
      "metadata": {
        "id": "06848020"
      },
      "source": [
        "## 1. Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5604d36a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5604d36a",
        "outputId": "dc7c5303-82b5-46f8-9d81-73412a4e8b8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully.\n"
          ]
        }
      ],
      "source": [
        "# Core Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Models\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Misc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries imported successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbe7cac7",
      "metadata": {
        "id": "bbe7cac7"
      },
      "source": [
        "## 2. Data Loading\n",
        "\n",
        "In this section, you will connect to your dataset.  \n",
        "You can either:\n",
        "\n",
        "- Mount Google Drive and point to a folder of images organized by skin tone labels, or  \n",
        "- Clone your GitHub repo that contains the dataset.\n",
        "\n",
        "Update the `data_path` variable below to match your dataset location.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "670ccfde",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "670ccfde",
        "outputId": "bb31a043-aef4-4567-f529-13f4417ce9ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Data path set to: /content/drive/MyDrive/MelaninMatchAI/data/images\n",
            "Categories: ['light', 'tan', 'medium', 'deep', 'dark']\n"
          ]
        }
      ],
      "source": [
        "# If using Google Drive, uncomment and run this:\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# TODO: Update this path to your actual dataset\n",
        "# Example structure:\n",
        "# data_path/light, data_path/tan, data_path/medium, data_path/deep, data_path/dark\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/MelaninMatchAI/data/images\"  # CHANGE THIS TO YOUR FOLDER\n",
        "\n",
        "categories = ['light', 'tan', 'medium', 'deep', 'dark']\n",
        "\n",
        "print(\"Data path set to:\", data_path)\n",
        "print(\"Categories:\", categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c92c2d0",
      "metadata": {
        "id": "0c92c2d0"
      },
      "source": [
        "### 2.1 Preview a Sample Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "800e56e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "800e56e0",
        "outputId": "5200b88a-1e04-4f0d-d590-e9e76eb6ba41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder not found for category 'light': /content/drive/MyDrive/MelaninMatchAI/data/images/light\n",
            "Folder not found for category 'tan': /content/drive/MyDrive/MelaninMatchAI/data/images/tan\n",
            "Folder not found for category 'medium': /content/drive/MyDrive/MelaninMatchAI/data/images/medium\n",
            "Folder not found for category 'deep': /content/drive/MyDrive/MelaninMatchAI/data/images/deep\n",
            "Folder not found for category 'dark': /content/drive/MyDrive/MelaninMatchAI/data/images/dark\n"
          ]
        }
      ],
      "source": [
        "# This will try to preview one sample image from each category (if available)\n",
        "for label in categories:\n",
        "    folder = os.path.join(data_path, label)\n",
        "    if not os.path.isdir(folder):\n",
        "        print(f\"Folder not found for category '{label}':\", folder)\n",
        "        continue\n",
        "\n",
        "    files = os.listdir(folder)\n",
        "    if len(files) == 0:\n",
        "        print(f\"No images found in folder for '{label}'\")\n",
        "        continue\n",
        "\n",
        "    img_path = os.path.join(folder, files[0])\n",
        "    img = cv2.imread(img_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.title(f\"Sample Image - {label}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "551180ff",
      "metadata": {
        "id": "551180ff"
      },
      "source": [
        "## 3. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94cd661f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "94cd661f",
        "outputId": "0b2389cb-add9-4314-cf77-ea63f92b3cd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARNING] Skipping missing folder for category 'light': /content/drive/MyDrive/MelaninMatchAI/data/images/light\n",
            "[WARNING] Skipping missing folder for category 'tan': /content/drive/MyDrive/MelaninMatchAI/data/images/tan\n",
            "[WARNING] Skipping missing folder for category 'medium': /content/drive/MyDrive/MelaninMatchAI/data/images/medium\n",
            "[WARNING] Skipping missing folder for category 'deep': /content/drive/MyDrive/MelaninMatchAI/data/images/deep\n",
            "[WARNING] Skipping missing folder for category 'dark': /content/drive/MyDrive/MelaninMatchAI/data/images/dark\n",
            "Dataset size: (0,) (0,)\n",
            "Encoded classes: []\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4035852336.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Train-test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_encoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2852\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2482\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ],
      "source": [
        "IMG_SIZE = (128, 128)\n",
        "X, y = [], []\n",
        "\n",
        "for label in categories:\n",
        "    folder = os.path.join(data_path, label)\n",
        "    if not os.path.isdir(folder):\n",
        "        print(f\"[WARNING] Skipping missing folder for category '{label}':\", folder)\n",
        "        continue\n",
        "\n",
        "    for img_name in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, img_name)\n",
        "        try:\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                print(f\"[WARNING] Could not read image: {img_path}\")\n",
        "                continue\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            X.append(img)\n",
        "            y.append(label)\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] Failed on {img_path}: {e}\")\n",
        "\n",
        "X = np.array(X) / 255.0\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"Dataset size:\", X.shape, y.shape)\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "print(\"Encoded classes:\", le.classes_)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "print(\"Train set:\", X_train.shape, \"Test set:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3802b187",
      "metadata": {
        "id": "3802b187"
      },
      "source": [
        "## 4. Baseline Model — SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32b795f8",
      "metadata": {
        "id": "32b795f8"
      },
      "outputs": [],
      "source": [
        "# Flatten images for classical machine learning models\n",
        "X_train_flat = X_train.reshape(len(X_train), -1)\n",
        "X_test_flat = X_test.reshape(len(X_test), -1)\n",
        "\n",
        "svm_model = SVC(kernel='linear', C=1)\n",
        "svm_model.fit(X_train_flat, y_train)\n",
        "\n",
        "y_pred_svm = svm_model.predict(X_test_flat)\n",
        "\n",
        "print(\"=== SVM Classification Report ===\")\n",
        "print(classification_report(y_test, y_pred_svm, target_names=le.classes_))\n",
        "\n",
        "print(\"=== SVM Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, y_pred_svm))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06fbcb9d",
      "metadata": {
        "id": "06fbcb9d"
      },
      "source": [
        "## 5. Baseline Model — kNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90044288",
      "metadata": {
        "id": "90044288"
      },
      "outputs": [],
      "source": [
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train_flat, y_train)\n",
        "\n",
        "y_pred_knn = knn_model.predict(X_test_flat)\n",
        "\n",
        "print(\"=== kNN Classification Report ===\")\n",
        "print(classification_report(y_test, y_pred_knn, target_names=le.classes_))\n",
        "\n",
        "print(\"=== kNN Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, y_pred_knn))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28267fc7",
      "metadata": {
        "id": "28267fc7"
      },
      "source": [
        "## 6. Deep Learning Model — CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e670993b",
      "metadata": {
        "id": "e670993b"
      },
      "outputs": [],
      "source": [
        "cnn_model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(len(categories), activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "843df079",
      "metadata": {
        "id": "843df079"
      },
      "source": [
        "### 6.1 Training the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd161f1e",
      "metadata": {
        "id": "fd161f1e"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10  # You can increase this for better performance\n",
        "\n",
        "history = cnn_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(X_test, y_test)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d198766c",
      "metadata": {
        "id": "d198766c"
      },
      "source": [
        "### 6.2 Training & Validation Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "533b706d",
      "metadata": {
        "id": "533b706d"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc8e59d2",
      "metadata": {
        "id": "bc8e59d2"
      },
      "source": [
        "### 6.3 CNN Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6401d3b6",
      "metadata": {
        "id": "6401d3b6"
      },
      "outputs": [],
      "source": [
        "y_pred_cnn_probs = cnn_model.predict(X_test)\n",
        "y_pred_cnn = np.argmax(y_pred_cnn_probs, axis=1)\n",
        "\n",
        "print(\"=== CNN Classification Report ===\")\n",
        "print(classification_report(y_test, y_pred_cnn, target_names=le.classes_))\n",
        "\n",
        "print(\"=== CNN Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, y_pred_cnn))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6ba7edf",
      "metadata": {
        "id": "f6ba7edf"
      },
      "source": [
        "## 7. Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cde2e6bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "cde2e6bc",
        "outputId": "ec06e40c-f46e-41e8-c36a-1b40b803ba5b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cnn_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-53821294.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"melanin_match_ai_cnn.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model saved to {model_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cnn_model' is not defined"
          ]
        }
      ],
      "source": [
        "model_path = \"melanin_match_ai_cnn.h5\"\n",
        "cnn_model.save(model_path)\n",
        "print(f\"Model saved to {model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "711d5f66",
      "metadata": {
        "id": "711d5f66"
      },
      "source": [
        "## 8. Results & Discussion\n",
        "\n",
        "- Compare the performance of **SVM**, **kNN**, and the **CNN model** using accuracy and the classification reports.\n",
        "- Discuss which model performs best overall and which classes (skin tone categories) are hardest to classify.\n",
        "- Reflect on any class imbalance or misclassification patterns you observe in the confusion matrices.\n",
        "- You can copy key numbers and insights from this notebook into your final project report.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6655d0e7",
      "metadata": {
        "id": "6655d0e7"
      },
      "source": [
        "## 9. Conclusion & Future Work\n",
        "\n",
        "Summarize:\n",
        "\n",
        "- The goal of Melanin Match AI and what you achieved.\n",
        "- Which model is currently your best-performing model.\n",
        "- How this project supports fairness and inclusivity in shade matching.\n",
        "\n",
        "Future work ideas:\n",
        "\n",
        "- Use **transfer learning** with models like EfficientNet or ResNet for better performance.\n",
        "- Add **data augmentation** (brightness, contrast, rotations) to make the model more robust to lighting changes.\n",
        "- Collect more images for underrepresented skin tone categories to reduce bias.\n",
        "- Deploy the model through a simple web app so users can upload a photo and receive shade recommendations.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}